{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !apt update && apt install -y libsm6 libxext6\n",
    "\n",
    "# !apt-get install libxrender1\n",
    "# #!sudo apt-get install libfontconfig1 libxrender1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QEtVTK3uYk9p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, math\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p5mkJO53h-Zs"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.4 \n",
    "epochs = 25\n",
    "batch_size = 512\n",
    "end_percentage = 0.05\n",
    "triangle_tilt = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6WR3LO8tidAc",
    "outputId": "1a364e70-0ba3-43f9-fa61-5ecfb4e57b5e"
   },
   "outputs": [],
   "source": [
    "# Loading the CIFAR10 60000 Training and 10000 Test data into respective numpy arrays\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "n_train, n_test = X_train.shape[0], X_test.shape[0]\n",
    "img_size = X_train.shape[1]\n",
    "n_classes = y_train.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJq-7uMpmU6x"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n6QYdPNtQ99J",
    "outputId": "fadabed6-1362-47ed-9594-10188bbc53b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4914009  0.48215896 0.4465308 ] [0.24703279 0.24348423 0.26158753]\n"
     ]
    }
   ],
   "source": [
    "X_train_mean = np.mean(X_train, axis=(0,1,2))\n",
    "X_train_std = np.std(X_train, axis=(0,1,2))\n",
    "print(X_train_mean, X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pzRLfIA8Q-xx",
    "outputId": "febbced7-b822-4d37-8cbf-e407f62608d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49421427 0.4851322  0.45040992] [0.24665268 0.24289216 0.2615922 ]\n"
     ]
    }
   ],
   "source": [
    "X_test_mean = np.mean(X_test, axis=(0,1,2))\n",
    "X_test_std = np.std(X_test, axis=(0,1,2))\n",
    "print(X_test_mean, X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOh0j981RHnW"
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "X_test = (X_test - X_test_mean) / X_test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJDvRfVy3klC"
   },
   "source": [
    "#Random Cropping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOtVSU6qrjI9"
   },
   "outputs": [],
   "source": [
    "def random_crop(input_image,padding_pixels=4,random_crop_size=(32,32)):\n",
    "          # Note: image_data_format is 'channel_last'\n",
    "          assert input_image.shape[2] == 3\n",
    "          \n",
    "          #Pad by 4 pixels\n",
    "          img = cv2.copyMakeBorder(input_image, padding_pixels, padding_pixels, padding_pixels, padding_pixels, cv2.BORDER_REPLICATE)\n",
    "          \n",
    "          height, width = img.shape[0], img.shape[1]\n",
    "          dy, dx = random_crop_size\n",
    "          x = np.random.randint(0, width - dx + 1)\n",
    "          y = np.random.randint(0, height - dy + 1)\n",
    "          return img[y:(y+dy), x:(x+dx), :]\n",
    "        \n",
    "tr_seq = list(range(len(X_train)))\n",
    "train_func = lambda i:random_crop(X_train[i])\n",
    "train_features = list(map(train_func,tr_seq))\n",
    "\n",
    "train_features = np.asarray(train_features)\n",
    "train_labels = Y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDK_7gDlHEFC"
   },
   "outputs": [],
   "source": [
    "def get_cutout_eraser_and_padcrop(p=0.5, s_l=0.3, s_h=0.3, r_1=0.3, r_2=1 / 0.3, max_erasures_per_image=1, pixel_level=True, random_crop_size=(32, 32), padding_pixels=4):\n",
    "    \"\"\"\n",
    "    :param p:\n",
    "    :param s_l: Minimum Area Proportion of Original that may be cut\n",
    "    :param s_h: Maximum Area Proportion of Original that may be cut\n",
    "    :param r_1: Min Aspect Ratio\n",
    "    :param r_2: Max Aspect Ratio\n",
    "    :param max_erasures_per_image:\n",
    "    :param pixel_level:\n",
    "    :return: Eraser to be used as Preprocessing Function\n",
    "    \"\"\"\n",
    "    assert max_erasures_per_image >= 1\n",
    "\n",
    "    def eraser(input_img):\n",
    "        v_l = np.min(input_img)\n",
    "        v_h = np.max(input_img)\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        mx = np.random.randint(1, max_erasures_per_image + 1)\n",
    "        # print(\"Erasures = \",mx,end =\", \")\n",
    "        for i in range(mx):\n",
    "            while True:\n",
    "                s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "                r = np.random.uniform(r_1, r_2)\n",
    "                w = int(np.sqrt(s / r))\n",
    "                h = int(np.sqrt(s * r))\n",
    "                left = np.random.randint(0, img_w)\n",
    "                top = np.random.randint(0, img_h)\n",
    "\n",
    "                if left + w <= img_w and top + h <= img_h:\n",
    "                    break\n",
    "\n",
    "            # print(\"W = \",w,\"H = \",h,end =\", \")\n",
    "\n",
    "            if pixel_level:\n",
    "                # print(np.max(img_c),np.min(img_c),v_l,v_h)\n",
    "                c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "                # print(c.shape,np.min(c),np.max(c),np.median(c))\n",
    "            else:\n",
    "                c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "            input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        # print()\n",
    "        return input_img\n",
    "     \n",
    "    \n",
    "        \n",
    "    def preproc_image(input_image):\n",
    "      #return eraser\n",
    "      return eraser(input_image)\n",
    "\n",
    "    return preproc_image\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBPdtlO75o2O"
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "   #featurewise_center=True,\n",
    "   #featurewise_std_normalization=True,\n",
    "   horizontal_flip=0.5,                 # randomly flip images                                     \n",
    "   preprocessing_function=get_cutout_eraser_and_padcrop(p=0.8, s_l=0.25, s_h=0.25, r_1=0.2, r_2=1 / 0.3, max_erasures_per_image=1, pixel_level=False))\n",
    "\n",
    "_ = datagen.fit(X_train)\n",
    "train_iterator = datagen.flow(X_train, Y_train, batch_size=256, shuffle=False)\n",
    "\n",
    "# X_e, Y_e = train_iterator.next()\n",
    "# X_e = min_max_scale(X_e)\n",
    "# show_examples(X_e[0:10], Y_e[0:10], classes = get_cifar10_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxc5QhiQR1X6"
   },
   "outputs": [],
   "source": [
    "datagen_validation = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "datagen_validation.fit(X_test)\n",
    "validation_iterator = datagen_validation.flow(X_test, Y_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBjKmx1u4Nso"
   },
   "source": [
    "#Custom Image Data Generator for Augmentation \n",
    "\n",
    "Here storing all the augmented images and later will pick up half augmented from here and half from original images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "bp09LebQfo4O",
    "outputId": "6dc4fd46-a461-43ba-c424-2ace12f3d3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp  0\n",
      "tmp  50000\n",
      "tmp  100000\n",
      "tmp  150000\n",
      "tmp  200000\n",
      "tmp  250000\n",
      "tmp  300000\n",
      "tmp  350000\n",
      "tmp  400000\n",
      "tmp  450000\n",
      "tmp  500000\n",
      "tmp  550000\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File('aug_img.hdf5', 'w')\n",
    "d = f.create_dataset('dataset', (600000,32,32,3),chunks=(256,32,32,3))\n",
    "l = f.create_dataset('labels',(600000,10),chunks=(256,10))\n",
    "\n",
    "\n",
    "batch_size=256\n",
    "EPOCHS =12\n",
    "aug_lbl=[]\n",
    "tmp=0\n",
    "for i in range(EPOCHS):\n",
    "  print(\"tmp \", tmp)\n",
    "  for j in range(len(train_iterator)):\n",
    "    initial = j*batch_size+tmp\n",
    "    train_gen = train_iterator.next()\n",
    "    if(j == 195 ):\n",
    "      final += 80\n",
    "      d[initial:final]= train_gen[0]\n",
    "      l[initial:final]= train_gen[1]\n",
    "      continue \n",
    "      \n",
    "    \n",
    "    final = initial + 256\n",
    "    d[initial:final]= train_gen[0]\n",
    "    l[initial:final]= train_gen[1]\n",
    "  \n",
    "  tmp = final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10HGAQbDDg6d"
   },
   "outputs": [],
   "source": [
    "input_shape=(32, 32, 3)\n",
    "num_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tPD_H0K-4lHe"
   },
   "source": [
    "#David Net Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37S1oFpA2wUJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 16:57:00.708470 140451500074816 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "def block(input_layer,filters,stride=1):\n",
    "  \n",
    "  conv_1 = tf.keras.layers.Conv2D(filters, kernel_size=(3,3), padding='same', strides=stride, kernel_regularizer=l2(0.0001))(input_layer)\n",
    "  \n",
    "  bn_1 = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9,epsilon=1e-5)(conv_1)\n",
    "  \n",
    "  activation_layer_b1 = tf.keras.layers.Activation('relu')(bn_1)\n",
    "  \n",
    "  return activation_layer_b1\n",
    "\n",
    "\n",
    "input = tf.keras.layers.Input(shape=input_shape)\n",
    "start = block(input,32)\n",
    "\n",
    "layer_1 = block(start,64)\n",
    "mp_1 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(layer_1)\n",
    "\n",
    "layer1_identity = tf.keras.layers.Conv2D(filters=32,kernel_size=(1, 1),strides=(1, 1),padding=\"same\",kernel_regularizer=l2(0.0001))(mp_1)\n",
    "layer1_res1 = block(layer1_identity,64)\n",
    "layer1_res2 = block(layer1_res1,64)\n",
    "\n",
    "concat1 = tf.keras.layers.concatenate([mp_1, layer1_res2])\n",
    "\n",
    "layer_2 = block(concat1,128)\n",
    "mp_2 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(layer_2)\n",
    "\n",
    "layer_3 = block(mp_2,256)\n",
    "mp_3 = tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(layer_3)\n",
    "\n",
    "layer3_identity = tf.keras.layers.Conv2D(filters=128,kernel_size=(1, 1),strides=(1, 1),padding=\"same\",kernel_regularizer=l2(0.0001))(mp_3)\n",
    "layer3_res1 = block(layer3_identity,256)\n",
    "layer3_res2 = block(layer3_res1,256)\n",
    "\n",
    "concat2 = tf.keras.layers.concatenate([mp_3, layer3_res2])\n",
    "\n",
    "gmp = tf.keras.layers.GlobalAveragePooling2D()(concat2)\n",
    "dense = tf.keras.layers.Dense(units=num_outputs, activation=\"softmax\")(gmp) #kernel_initializer=\"he_normal\", \n",
    "\n",
    "model = tf.keras.models.Model(inputs=input, outputs=dense)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "glb550Vu5AJe"
   },
   "source": [
    "#For slanted learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "suxU4w1SF6EX",
    "outputId": "bcd14ad7-23d6-4d37-f5ed-bbe2e2f7010e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def min_max_scaler(iterations, num_iterations, end_percentage, min_val, max_val, invert = False, triangle_tilt = 0.65):\n",
    "  non_slant_mid_cycle_id = int(num_iterations * ((1. - end_percentage)) / float(2))\n",
    "  mid_cycle_id = int(triangle_tilt*int(num_iterations * ((1. - end_percentage)) / float(2)))\n",
    "  value = 0\n",
    "  if iterations > 2 * non_slant_mid_cycle_id:\n",
    "    \n",
    "    \n",
    "      extra_iters = (iterations - 2 * non_slant_mid_cycle_id)\n",
    "      current_percentage = 1 - (1 - 1/10)*extra_iters/(num_iterations - 2 * non_slant_mid_cycle_id)\n",
    "            \n",
    "\n",
    "  elif iterations >  mid_cycle_id:\n",
    "      current_percentage = 1. - (iterations - mid_cycle_id) / (2*non_slant_mid_cycle_id - mid_cycle_id)\n",
    "      \n",
    "  else:\n",
    "      current_percentage = iterations / mid_cycle_id\n",
    "      \n",
    "  if invert:\n",
    "    if iterations > 2 * non_slant_mid_cycle_id:\n",
    "      return max_val\n",
    "    return max_val - current_percentage * (max_val - min_val)\n",
    "  else:\n",
    "    if iterations > 2 * non_slant_mid_cycle_id:\n",
    "      return min_val * current_percentage\n",
    "    return min_val + current_percentage * (max_val - min_val)\n",
    "  \n",
    "    \n",
    "\n",
    "print(\"=\"*80)\n",
    "scales = []\n",
    "for i in range(1000):\n",
    "  p = min_max_scaler(i,1000,0.1,min_val=0.1,max_val=1, invert=False)\n",
    "  scales.append(p)\n",
    "  \n",
    "plt.plot(np.array(scales))\n",
    "plt.title(\"LR Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_zaj292F7PD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "\n",
    "\n",
    "# Code is ported from https://github.com/fastai/fastai\n",
    "class OneCycleLR(Callback):\n",
    "    def __init__(self,\n",
    "                 epochs,\n",
    "                 batch_size,\n",
    "                 samples,\n",
    "                 steps,\n",
    "                 max_lr,\n",
    "                 end_percentage=0.1,\n",
    "                 scale=100,\n",
    "                 maximum_momentum=0.95,\n",
    "                 minimum_momentum=0.85,\n",
    "                 triangle_tilt = 0.75,\n",
    "                 verbose=True):\n",
    "        \"\"\" This callback implements a cyclical learning rate policy (CLR).\n",
    "        This is a special case of Cyclic Learning Rates, where we have only 1 cycle.\n",
    "        After the completion of 1 cycle, the learning rate will decrease rapidly to\n",
    "        100th its initial lowest value.\n",
    "        # Arguments:\n",
    "            max_lr: Float. Initial learning rate. This also sets the\n",
    "                starting learning rate (which will be 10x smaller than\n",
    "                this), and will increase to this value during the first cycle.\n",
    "            end_percentage: Float. The percentage of all the epochs of training\n",
    "                that will be dedicated to sharply decreasing the learning\n",
    "                rate after the completion of 1 cycle. Must be between 0 and 1.\n",
    "            scale_percentage: Float or None. If float, must be between 0 and 1.\n",
    "                If None, it will compute the scale_percentage automatically\n",
    "                based on the `end_percentage`.\n",
    "            maximum_momentum: Optional. Sets the maximum momentum (initial)\n",
    "                value, which gradually drops to its lowest value in half-cycle,\n",
    "                then gradually increases again to stay constant at this max value.\n",
    "                Can only be used with SGD Optimizer.\n",
    "            minimum_momentum: Optional. Sets the minimum momentum at the end of\n",
    "                the half-cycle. Can only be used with SGD Optimizer.\n",
    "            verbose: Bool. Whether to print the current learning rate after every\n",
    "                epoch.\n",
    "        # Reference\n",
    "            - [A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, weight_decay, and weight decay](https://arxiv.org/abs/1803.09820)\n",
    "            - [Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates](https://arxiv.org/abs/1708.07120)\n",
    "        \"\"\"\n",
    "        super(OneCycleLR, self).__init__()\n",
    "\n",
    "        if end_percentage < 0. or end_percentage > 1.:\n",
    "            raise ValueError(\"`end_percentage` must be between 0 and 1\")\n",
    "\n",
    "\n",
    "        self.initial_lr = max_lr\n",
    "        self.end_percentage = end_percentage\n",
    "        self.scale = scale\n",
    "        self.max_momentum = maximum_momentum\n",
    "        self.min_momentum = minimum_momentum\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if self.max_momentum is not None and self.min_momentum is not None:\n",
    "            self._update_momentum = True\n",
    "        else:\n",
    "            self._update_momentum = False\n",
    "\n",
    "        self.clr_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.samples = samples\n",
    "        self.steps = steps\n",
    "        self.num_iterations = None\n",
    "        self.mid_cycle_id = None\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"\n",
    "        Reset the callback.\n",
    "        \"\"\"\n",
    "        self.clr_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "    def compute_lr(self):\n",
    "        \"\"\"\n",
    "        Compute the learning rate based on which phase of the cycle it is in.\n",
    "        - If in the first half of training, the learning rate gradually increases.\n",
    "        - If in the second half of training, the learning rate gradually decreases.\n",
    "        - If in the final `end_percentage` portion of training, the learning rate\n",
    "            is quickly reduced to near 100th of the original min learning rate.\n",
    "        # Returns:\n",
    "            the new learning rate\n",
    "        \"\"\"\n",
    "        new_lr = min_max_scaler(self.clr_iterations, self.num_iterations, self.end_percentage, self.initial_lr/self.scale, self.initial_lr, invert = False, triangle_tilt=triangle_tilt)\n",
    "        return new_lr\n",
    "\n",
    "    def compute_momentum(self):\n",
    "        \"\"\"\n",
    "         Compute the momentum based on which phase of the cycle it is in.\n",
    "        - If in the first half of training, the momentum gradually decreases.\n",
    "        - If in the second half of training, the momentum gradually increases.\n",
    "        - If in the final `end_percentage` portion of training, the momentum value\n",
    "            is kept constant at the maximum initial value.\n",
    "        # Returns:\n",
    "            the new momentum value\n",
    "        \"\"\"    \n",
    "        new_momentum = min_max_scaler(self.clr_iterations, self.num_iterations, self.end_percentage, self.min_momentum, self.max_momentum, invert = True, triangle_tilt=triangle_tilt)\n",
    "        return new_momentum\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.steps is not None:\n",
    "            self.num_iterations = self.epochs * self.steps\n",
    "        else:\n",
    "            if (self.samples % self.batch_size) == 0:\n",
    "                remainder = 0\n",
    "            else:\n",
    "                remainder = 1\n",
    "            self.num_iterations = (self.epochs + remainder) * self.samples // self.batch_size\n",
    "\n",
    "        self.mid_cycle_id = int(self.num_iterations * ((1. - self.end_percentage)) / float(2))\n",
    "\n",
    "        self._reset()\n",
    "        K.set_value(self.model.optimizer.lr, self.compute_lr())\n",
    "\n",
    "        if self._update_momentum:\n",
    "            if not hasattr(self.model.optimizer, 'momentum'):\n",
    "                raise ValueError(\"Momentum can be updated only on SGD optimizer !\")\n",
    "\n",
    "            new_momentum = self.compute_momentum()\n",
    "            K.set_value(self.model.optimizer.momentum, new_momentum)\n",
    "\n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "\n",
    "        self.clr_iterations += 1\n",
    "        new_lr = self.compute_lr()\n",
    "\n",
    "        self.history.setdefault('lr', []).append(\n",
    "            K.get_value(self.model.optimizer.lr))\n",
    "        K.set_value(self.model.optimizer.lr, new_lr)\n",
    "\n",
    "        if self._update_momentum:\n",
    "            if not hasattr(self.model.optimizer, 'momentum'):\n",
    "                raise ValueError(\"Momentum can be updated only on SGD optimizer !\")\n",
    "\n",
    "            new_momentum = self.compute_momentum()\n",
    "\n",
    "            self.history.setdefault('momentum', []).append(\n",
    "                K.get_value(self.model.optimizer.momentum))\n",
    "            K.set_value(self.model.optimizer.momentum, new_momentum)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.verbose:\n",
    "            if self._update_momentum:\n",
    "                print(\" - lr: %0.5f - momentum: %0.2f \" %\n",
    "                      (self.history['lr'][-1], self.history['momentum'][-1]))\n",
    "\n",
    "            else:\n",
    "                print(\" - lr: %0.5f \" % (self.history['lr'][-1]))\n",
    "                \n",
    "    \n",
    "    def plot(self):\n",
    "        plt.title(\"LR-Plot\")\n",
    "        plt.plot(self.history['lr'])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"LR\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(\"Momentum-Plot\")\n",
    "        plt.plot(self.history['momentum'])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Momentum\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITkvgtgP5Gjt"
   },
   "source": [
    "#One Cycle LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NblM6VSGBNm"
   },
   "outputs": [],
   "source": [
    "olr = OneCycleLR(epochs=24, batch_size = batch_size,steps=98, \n",
    "                 samples=X_train.shape[0], max_lr=0.6, verbose = True, scale = 50, end_percentage=0.1,\n",
    "                 maximum_momentum = 0.95, minimum_momentum=0.85, triangle_tilt=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWaEbb0BlBK_"
   },
   "outputs": [],
   "source": [
    "sgd = tf.keras.optimizers.SGD(lr=0.08, decay=5e-4, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldAyybd45OkJ"
   },
   "source": [
    "#Reading the HDF5 file of Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsdzrKXZglo8"
   },
   "outputs": [],
   "source": [
    "data = tf.keras.utils.HDF5Matrix('./aug_img.hdf5','dataset')\n",
    "label = tf.keras.utils.HDF5Matrix('./aug_img.hdf5','labels')\n",
    "\n",
    "# f = h5py.File('aug_img.hdf5', 'r')\n",
    "# data = f['dataset'][:]\n",
    "# label = f['labels'][:]\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30N0gOJz5ZAY"
   },
   "source": [
    "#Custom Data Generator \n",
    "\n",
    "It picks Half of batch from Augmented images and other half from \n",
    "\n",
    "Original Images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4teA41AsgUid"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import keras\n",
    "import random\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, label, train_features,train_labels, batch_size=512, dim=(32,32), n_channels=3,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.label = label\n",
    "        self.data = data\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.train_features = train_features\n",
    "        self.train_labels = train_labels\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        #indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        aug_ran = random.randrange(0,len(self.data)-256)\n",
    "        wo_aug = random.randrange(0,len(self.train_features)-256)\n",
    "        #print(aug_ran)\n",
    "        train_data_aug = lambda i: (np.array(self.data[i:i+256]),np.array(self.label[i:i+256]))\n",
    "        train_data_wo = lambda i: (np.array(self.train_features[i:i+256]),np.array(self.train_labels[i:i+256]))\n",
    "        \n",
    "        \n",
    "        X = np.concatenate((train_data_aug(aug_ran)[0],train_data_wo(wo_aug)[0]),axis=0)\n",
    "        y = np.concatenate((train_data_aug(aug_ran)[1],train_data_wo(wo_aug)[1]),axis=0)\n",
    "        #print(\"label\",y.shape, \" \" ,X.shape)\n",
    "        #plt.imshow(X[0])\n",
    "        # Generate data\n",
    "        #X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "gen = DataGenerator(data,label,train_features,train_labels,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HaDjaDz3szBx",
    "outputId": "59c9e4b9-11cd-49ef-e96d-c0da3b4e72e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.6224 - acc: 0.4531 - lr: 0.08908 - momentum: 0.94 \n",
      "98/98 [==============================] - 10s 106ms/step - loss: 1.6151 - acc: 0.4562 - val_loss: 1.3745 - val_acc: 0.5565\n",
      "Epoch 2/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.1243 - acc: 0.6390 - lr: 0.16695 - momentum: 0.92 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 1.1218 - acc: 0.6401 - val_loss: 1.3654 - val_acc: 0.6007\n",
      "Epoch 3/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.9232 - acc: 0.7179 - lr: 0.24482 - momentum: 0.91 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.9214 - acc: 0.7185 - val_loss: 0.9263 - val_acc: 0.7388\n",
      "Epoch 4/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.8302 - acc: 0.7566 - lr: 0.32269 - momentum: 0.90 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.8299 - acc: 0.7568 - val_loss: 0.9556 - val_acc: 0.7251\n",
      "Epoch 5/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.7778 - acc: 0.7787 - lr: 0.40056 - momentum: 0.88 \n",
      "98/98 [==============================] - 5s 49ms/step - loss: 0.7767 - acc: 0.7789 - val_loss: 0.8052 - val_acc: 0.7885\n",
      "Epoch 6/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.7245 - acc: 0.8028 - lr: 0.47843 - momentum: 0.87 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.7240 - acc: 0.8030 - val_loss: 0.9380 - val_acc: 0.7564\n",
      "Epoch 7/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6773 - acc: 0.8215 - lr: 0.55630 - momentum: 0.86 \n",
      "98/98 [==============================] - 5s 49ms/step - loss: 0.6767 - acc: 0.8217 - val_loss: 0.8936 - val_acc: 0.7710\n",
      "Epoch 8/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.6499 - acc: 0.8316 - lr: 0.58162 - momentum: 0.85 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.6499 - acc: 0.8315 - val_loss: 0.8669 - val_acc: 0.7943\n",
      "Epoch 9/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.8520 - lr: 0.53975 - momentum: 0.86 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.6036 - acc: 0.8520 - val_loss: 0.6994 - val_acc: 0.8347\n",
      "Epoch 10/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.8604 - lr: 0.49787 - momentum: 0.87 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.5772 - acc: 0.8601 - val_loss: 0.6574 - val_acc: 0.8456\n",
      "Epoch 11/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.5409 - acc: 0.8753 - lr: 0.45599 - momentum: 0.87 \n",
      "98/98 [==============================] - 5s 49ms/step - loss: 0.5400 - acc: 0.8757 - val_loss: 0.7038 - val_acc: 0.8353\n",
      "Epoch 12/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.5303 - acc: 0.8781 - lr: 0.41411 - momentum: 0.88 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.5309 - acc: 0.8781 - val_loss: 0.6456 - val_acc: 0.8489\n",
      "Epoch 13/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.4898 - acc: 0.8921 - lr: 0.37224 - momentum: 0.89 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.4895 - acc: 0.8921 - val_loss: 0.7045 - val_acc: 0.8369\n",
      "Epoch 14/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4775 - acc: 0.8966 - lr: 0.33036 - momentum: 0.90 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.4777 - acc: 0.8964 - val_loss: 0.6525 - val_acc: 0.8512\n",
      "Epoch 15/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.9078 - lr: 0.28848 - momentum: 0.90 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.4492 - acc: 0.9081 - val_loss: 0.6428 - val_acc: 0.8513\n",
      "Epoch 16/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.9096 - lr: 0.24660 - momentum: 0.91 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.4386 - acc: 0.9095 - val_loss: 0.5789 - val_acc: 0.8773\n",
      "Epoch 17/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.9178 - lr: 0.20472 - momentum: 0.92 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.4137 - acc: 0.9177 - val_loss: 0.5776 - val_acc: 0.8794\n",
      "Epoch 18/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.3874 - acc: 0.9270 - lr: 0.16285 - momentum: 0.92 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.3861 - acc: 0.9274 - val_loss: 0.5626 - val_acc: 0.8803\n",
      "Epoch 19/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.9317 - lr: 0.12097 - momentum: 0.93 \n",
      "98/98 [==============================] - 5s 49ms/step - loss: 0.3686 - acc: 0.9319 - val_loss: 0.5157 - val_acc: 0.8936\n",
      "Epoch 20/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3394 - acc: 0.9427 - lr: 0.07909 - momentum: 0.94 \n",
      "98/98 [==============================] - 5s 49ms/step - loss: 0.3388 - acc: 0.9429 - val_loss: 0.5052 - val_acc: 0.8981\n",
      "Epoch 21/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.3094 - acc: 0.9520 - lr: 0.03721 - momentum: 0.95 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.3093 - acc: 0.9520 - val_loss: 0.5004 - val_acc: 0.8992\n",
      "Epoch 22/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.9563 - lr: 0.01022 - momentum: 0.95 \n",
      "98/98 [==============================] - 5s 51ms/step - loss: 0.2970 - acc: 0.9566 - val_loss: 0.4718 - val_acc: 0.9074\n",
      "Epoch 23/24\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.2811 - acc: 0.9610 - lr: 0.00573 - momentum: 0.95 \n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.2809 - acc: 0.9609 - val_loss: 0.4672 - val_acc: 0.9090\n",
      "Epoch 24/24\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.2760 - acc: 0.9632 - lr: 0.00125 - momentum: 0.95 \n",
      "98/98 [==============================] - 5s 51ms/step - loss: 0.2762 - acc: 0.9631 - val_loss: 0.4649 - val_acc: 0.9088\n",
      "Model took 124.49 seconds to train\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "start = time.time()\n",
    "# Train the model\n",
    "\n",
    "model_info = model.fit_generator(gen,\n",
    "                                 steps_per_epoch = 98, epochs = 24, \n",
    "                                 validation_data = validation_iterator, \n",
    "                                 validation_steps = len(validation_iterator),\n",
    "                                 verbose=1, callbacks=[olr])\n",
    "end = time.time()\n",
    "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
    "# plot model history\n",
    "# plot_model_history(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cgwIhCP8pe5_",
    "outputId": "a697fc72-5367-4d5b-be68-e91098c273b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4648878753185272, 0.9088]\n"
     ]
    }
   ],
   "source": [
    "# compute test accuracy\n",
    "result = model.evaluate_generator(validation_iterator, steps = len(validation_iterator))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqO7tjSmEsfL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Assignemnt-14",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
